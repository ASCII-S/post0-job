---
created: '2025-10-19'
last_reviewed: null
next_review: '2025-10-19'
review_count: 0
difficulty: medium
mastery_level: 0.0
tags:
- cuda
- cuda/如何实现并行前缀和？.md
related_outlines: []
---
# 如何实现并行前缀和？

## 面试标准答案

并行前缀和（Scan/Prefix Sum）有两种主要算法：**Hillis-Steele（工作非高效，O(nlogn)但延迟低）和Blelloch（工作高效，O(n)但需两阶段）**。Blelloch算法包括**上扫（Up-sweep）归约阶段**和**下扫（Down-sweep）分发阶段**，在共享内存中实现，然后多Block间通过递归或辅助数组处理。实际应用中Thrust和CUB提供了高度优化的实现，性能优于手写版本。包含式（Inclusive）和排除式（Exclusive）两种变体。

---

## 详细讲解

### 1. 前缀和问题定义

**Inclusive Scan（包含式）：**
```
输入：[a₀, a₁, a₂, a₃, a₄, ...]
输出：[a₀, a₀+a₁, a₀+a₁+a₂, a₀+a₁+a₂+a₃, ...]
```

**Exclusive Scan（排除式）：**
```
输入：[a₀, a₁, a₂, a₃, a₄, ...]
输出：[0, a₀, a₀+a₁, a₀+a₁+a₂, a₀+a₁+a₂+a₃, ...]
```

**应用场景：**
- Stream Compaction（数据压缩）
- 基数排序
- 快速排序分区
- 稀疏矩阵操作
- 分配内存偏移

### 2. Hillis-Steele算法（Inclusive Scan）

#### 2.1 原理

```
Step 0: [a₀, a₁, a₂, a₃, a₄, a₅, a₆, a₇]
Step 1: [a₀, a₀+a₁, a₁+a₂, a₂+a₃, a₃+a₄, a₄+a₅, a₅+a₆, a₆+a₇]
Step 2: [a₀, a₀+a₁, a₀+a₁+a₂, a₁+a₂+a₃, ...]
Step 3: [a₀, a₀+a₁, a₀+a₁+a₂, a₀+a₁+a₂+a₃, ...]
...
```

每步的偏移量翻倍：1, 2, 4, 8...

#### 2.2 实现

```cuda
__global__ void hillis_steele_scan(float *in, float *out, int n) {
    extern __shared__ float temp[];
    
    int tid = threadIdx.x;
    int pout = 0, pin = 1;
    
    // 加载输入到共享内存
    temp[tid] = (tid < n) ? in[tid] : 0;
    __syncthreads();
    
    for (int offset = 1; offset < n; offset *= 2) {
        pout = 1 - pout;  // 乒乓缓冲
        pin = 1 - pin;
        
        if (tid >= offset)
            temp[pout * n + tid] = temp[pin * n + tid] + temp[pin * n + tid - offset];
        else
            temp[pout * n + tid] = temp[pin * n + tid];
        
        __syncthreads();
    }
    
    if (tid < n)
        out[tid] = temp[pout * n + tid];
}
```

**特点：**
- 步骤数：O(log n)
- 总操作数：O(n log n) - **不是工作高效的**
- 优点：延迟低
- 缺点：需要2倍共享内存（乒乓缓冲）

### 3. Blelloch算法（工作高效）

#### 3.1 原理

**两阶段算法：**

**阶段1：Up-sweep（归约）**
```
输入：[a₀, a₁, a₂, a₃, a₄, a₅, a₆, a₇]

Step 1: [a₀, a₀+a₁, a₂, a₂+a₃, a₄, a₄+a₅, a₆, a₆+a₇]
Step 2: [a₀, a₀+a₁, a₂, a₀+a₁+a₂+a₃, a₄, a₄+a₅, a₆, a₄+a₅+a₆+a₇]
Step 3: [a₀, a₀+a₁, a₂, a₀+a₁+a₂+a₃, a₄, a₄+a₅, a₆, SUM]

最后一个元素 = 总和
```

**阶段2：Down-sweep（分发）**
```
从顶向下传播部分和

最终：[0, a₀, a₀+a₁, a₀+a₁+a₂, ...] (Exclusive Scan)
```

#### 3.2 实现

```cuda
__global__ void blelloch_scan(float *in, float *out, int n) {
    extern __shared__ float temp[];
    
    int tid = threadIdx.x;
    int offset = 1;
    
    // 加载输入
    temp[2*tid] = in[2*tid];
    temp[2*tid + 1] = in[2*tid + 1];
    
    // Up-sweep（归约阶段）
    for (int d = n >> 1; d > 0; d >>= 1) {
        __syncthreads();
        if (tid < d) {
            int ai = offset * (2*tid + 1) - 1;
            int bi = offset * (2*tid + 2) - 1;
            temp[bi] += temp[ai];
        }
        offset *= 2;
    }
    
    // 清零最后一个元素（开始down-sweep）
    if (tid == 0) temp[n - 1] = 0;
    
    // Down-sweep（分发阶段）
    for (int d = 1; d < n; d *= 2) {
        offset >>= 1;
        __syncthreads();
        if (tid < d) {
            int ai = offset * (2*tid + 1) - 1;
            int bi = offset * (2*tid + 2) - 1;
            
            float t = temp[ai];
            temp[ai] = temp[bi];
            temp[bi] += t;
        }
    }
    __syncthreads();
    
    // 写回结果
    out[2*tid] = temp[2*tid];
    out[2*tid + 1] = temp[2*tid + 1];
}
```

**特点：**
- 步骤数：2 × O(log n)
- 总操作数：O(n) - **工作高效**
- 优点：操作数少，适合大数据
- 缺点：延迟稍高（两阶段）

### 4. 多Block Scan

单个Block只能处理有限数量（如2048）元素，大数组需要多Block策略：

#### 4.1 三阶段方法

```cuda
// 阶段1：每个Block独立scan
__global__ void scan_blocks(float *in, float *out, float *block_sums, int n) {
    extern __shared__ float temp[];
    int bid = blockIdx.x;
    int tid = threadIdx.x;
    int i = bid * blockDim.x + tid;
    
    // Block内scan
    blelloch_scan_kernel(temp, i < n ? in[i] : 0);
    
    // 保存Block的总和
    if (tid == blockDim.x - 1) {
        block_sums[bid] = temp[tid] + in[i];  // 最后元素+自身=总和
    }
    
    if (i < n) out[i] = temp[tid];
}

// 阶段2：Scan block_sums
__global__ void scan_block_sums(float *block_sums, int num_blocks) {
    // 对Block总和做scan（通常足够小，单Block即可）
    blelloch_scan_kernel(...);
}

// 阶段3：加上前面Block的累计值
__global__ void add_block_sums(float *out, float *block_sums, int n) {
    int bid = blockIdx.x;
    int i = bid * blockDim.x + threadIdx.x;
    
    if (bid > 0 && i < n) {
        out[i] += block_sums[bid - 1];
    }
}

// Host调用
scan_blocks<<<num_blocks, block_size>>>(d_in, d_out, d_block_sums, n);
scan_block_sums<<<1, num_blocks>>>(d_block_sums, num_blocks);
add_block_sums<<<num_blocks, block_size>>>(d_out, d_block_sums, n);
```

### 5. 使用Warp-level Primitives

```cuda
__inline__ __device__
int warpScanInclusive(int val) {
    for (int offset = 1; offset < 32; offset *= 2) {
        int n = __shfl_up_sync(0xffffffff, val, offset);
        if (threadIdx.x % 32 >= offset)
            val += n;
    }
    return val;
}

__inline__ __device__
int blockScanInclusive(int val) {
    static __shared__ int shared[32];
    int lane = threadIdx.x % 32;
    int wid = threadIdx.x / 32;
    
    // Warp内scan
    val = warpScanInclusive(val);
    
    // 每个warp的最后一个值
    if (lane == 31) shared[wid] = val;
    __syncthreads();
    
    // 第一个warp对warp总和做scan
    if (wid == 0) {
        int warp_sum = (threadIdx.x < blockDim.x / 32) ? shared[lane] : 0;
        warp_sum = warpScanInclusive(warp_sum);
        shared[lane] = warp_sum;
    }
    __syncthreads();
    
    // 加上前面warp的总和
    if (wid > 0)
        val += shared[wid - 1];
    
    return val;
}
```

### 6. 应用示例

#### 6.1 Stream Compaction

```cuda
// 压缩数组，只保留满足条件的元素
__global__ void stream_compact(int *in, int *out, int *flags, int *scan, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    
    if (i < n && flags[i]) {
        out[scan[i]] = in[i];  // scan结果即为输出位置
    }
}

// 使用：
// 1. 生成flags：flags[i] = (in[i] > threshold) ? 1 : 0
// 2. Scan flags得到输出位置
// 3. Compact
```

#### 6.2 快速排序分区

```cuda
__global__ void partition(int *in, int *out, int pivot, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    
    // 标记小于pivot的元素
    int less_than = (i < n && in[i] < pivot) ? 1 : 0;
    int scan_result = blockScanExclusive(less_than);
    
    // 计算总数
    __shared__ int total_less;
    if (threadIdx.x == blockDim.x - 1) {
        total_less = scan_result + less_than;
    }
    __syncthreads();
    
    // 写入输出位置
    if (i < n) {
        if (in[i] < pivot) {
            out[scan_result] = in[i];
        } else {
            out[total_less + (i - scan_result)] = in[i];
        }
    }
}
```

### 7. 性能对比

**测试：1M元素（V100）**

| 实现              | 时间(μs) | 带宽(GB/s) |
| ----------------- | -------- | ---------- |
| CPU串行           | 2500     | 1.6        |
| Hillis-Steele     | 180      | 22         |
| Blelloch（naive） | 95       | 42         |
| Blelloch优化      | 52       | 77         |
| Warp Shuffle      | 38       | 105        |
| CUB DeviceScan    | 28       | 143        |
| Thrust Scan       | 30       | 133        |

### 8. 使用Thrust/CUB（推荐）

#### 8.1 Thrust

```cpp
#include <thrust/scan.h>
#include <thrust/device_vector.h>

thrust::device_vector<int> d_in(N);
thrust::device_vector<int> d_out(N);

// Inclusive scan
thrust::inclusive_scan(d_in.begin(), d_in.end(), d_out.begin());

// Exclusive scan
thrust::exclusive_scan(d_in.begin(), d_in.end(), d_out.begin());

// 自定义操作（乘法scan）
thrust::inclusive_scan(d_in.begin(), d_in.end(), d_out.begin(), 
                       thrust::multiplies<int>());
```

#### 8.2 CUB

```cpp
#include <cub/cub.cuh>

// 分配临时存储
void *d_temp_storage = nullptr;
size_t temp_storage_bytes = 0;

// 第一次调用确定存储大小
cub::DeviceScan::ExclusiveSum(d_temp_storage, temp_storage_bytes, 
                               d_in, d_out, N);

// 分配
cudaMalloc(&d_temp_storage, temp_storage_bytes);

// 执行scan
cub::DeviceScan::ExclusiveSum(d_temp_storage, temp_storage_bytes,
                               d_in, d_out, N);
```

### 9. Inclusive vs Exclusive选择

| 应用场景          | 推荐类型  | 原因                  |
| ----------------- | --------- | --------------------- |
| 计算累计和        | Inclusive | 直接得到结果          |
| 内存分配/索引     | Exclusive | 第i个元素偏移=scan[i] |
| Stream Compaction | Exclusive | 输出位置从0开始       |
| 分区操作          | Exclusive | 左右分区边界明确      |

**转换：**
```cuda
// Inclusive → Exclusive
exclusive[i] = (i == 0) ? 0 : inclusive[i-1];

// Exclusive → Inclusive  
inclusive[i] = exclusive[i] + input[i];
```

### 10. 优化要点

| 优化技术          | 效果 | 实现难度 |
| ----------------- | ---- | -------- |
| Warp Shuffle      | 1.5× | 中       |
| 避免Bank Conflict | 1.2× | 中       |
| 多元素/线程       | 1.3× | 低       |
| 减少同步          | 1.1× | 低       |
| 使用CUB/Thrust    | 2-3× | 极低     |

### 11. 最佳实践

| 建议                        | 说明               |
| --------------------------- | ------------------ |
| ✅ 优先使用CUB或Thrust       | 高度优化，维护良好 |
| ✅ 小数组用Blelloch          | 工作高效           |
| ✅ 需要低延迟用Hillis-Steele | 步骤少             |
| ✅ 现代GPU用Warp Shuffle     | 性能最佳           |
| ✅ 注意处理非2幂次大小       | padding或特殊处理  |
| ❌ 不要忽视多Block策略       | 大数组必需         |

### 12. 记忆口诀

**"前缀和算法两大类，Hillis快Blelloch省；Up-sweep归约Down-sweep发，两阶段完成工作高效；多Block需要三步走，block内扫描sum再扫描；Warp Shuffle现代法，CUB Thrust最实用"**


---

## 相关笔记
<!-- 自动生成 -->

暂无相关笔记

